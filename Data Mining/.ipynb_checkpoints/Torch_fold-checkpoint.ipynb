{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abf3d86-beb1-4db7-8ded-eed87b506f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01f3be2f-d314-4965-9670-e863484ef330",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/clause/Desktop/QML/train.csv', index_col = 0)\n",
    "test = pd.read_csv('/Users/clause/Desktop/QML/test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6631a11-5537-47aa-8060-a63b4b4230f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.237158</td>\n",
       "      <td>-0.485387</td>\n",
       "      <td>-0.186567</td>\n",
       "      <td>-0.639733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.017201</td>\n",
       "      <td>-0.324686</td>\n",
       "      <td>0.515736</td>\n",
       "      <td>-0.158885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484542</td>\n",
       "      <td>0.234839</td>\n",
       "      <td>-0.537718</td>\n",
       "      <td>-0.701237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484542</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>-0.537718</td>\n",
       "      <td>0.584752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.271561</td>\n",
       "      <td>-0.488966</td>\n",
       "      <td>-0.186567</td>\n",
       "      <td>-0.530704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2         3         4         5         6    7  0.1\n",
       "0  0.652778  0.0  0.0  1.237158 -0.485387 -0.186567 -0.639733  0.0    0\n",
       "1  0.438889  0.0  0.0 -0.017201 -0.324686  0.515736 -0.158885  1.0    0\n",
       "2  0.466667  0.0  0.0  0.484542  0.234839 -0.537718 -0.701237  1.0    0\n",
       "3  0.166667  0.0  0.0  0.484542  0.047138 -0.537718  0.584752  1.0    0\n",
       "4  0.177778  0.0  0.0 -1.271561 -0.488966 -0.186567 -0.530704  1.0    0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40117dcf-a9d2-41f2-b2ec-c32524beadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns={'0.1': 'target'}, inplace=True)\n",
    "test.rename(columns={'0.1': 'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0363c5eb-b319-4102-a688-5fde9a9f0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train.iloc[:,:-1], train.iloc[:,-1], test.iloc[:,:-1], test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c505c1-d630-4d41-9482-1ae04365833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024cca40-21b8-441e-82f8-64092eb2bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452dab84-93e0-49a9-8f3c-9e9c2d7caa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = trainData(torch.FloatTensor(X_train.values),\n",
    "                       torch.FloatTensor(y_train.values))    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786a595f-3ddb-4bd8-b4b3-15085b0d82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02cf4383-4c7f-4547-b447-640bac35e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(8, 64)\n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_3 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = 0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] \n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "851546b2-e824-4464-9f17-3d89f22b0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########k折划分############        \n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据，分开放，X_train为训练数据，X_valid为验证数据\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k  # 每份的个数:数据总条数/折数（组数）\n",
    "    \n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)  #slice(start,end,step)切片函数\n",
    "        ##idx 为每组 valid\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i: ###第i折作valid\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat((X_train, X_part), dim=0) #dim=0增加行数，竖着连接\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    #print(X_train.size(),X_valid.size())\n",
    "    return X_train, y_train, X_valid,y_valid\n",
    " \n",
    " \n",
    "def k_fold(k, X_train, y_train, num_epochs=3, learning_rate=0.001, weight_decay=0.1, batch_size=5):\n",
    "    train_loss_sum, valid_loss_sum = 0, 0\n",
    "    train_acc_sum ,valid_acc_sum = 0,0\n",
    "    \n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train) # 获取k折交叉验证的训练和验证数据\n",
    "        net =  Net()  ### 实例化模型\n",
    "        ### 每份数据进行训练,体现步骤三####\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\\\n",
    "                                   weight_decay, batch_size) \n",
    "       \n",
    "        print('*'*25,'第',i+1,'折','*'*25)\n",
    "        print('train_loss:%.6f'%train_ls[-1][0],'train_acc:%.4f\\n'%valid_ls[-1][1],\\\n",
    "              'valid loss:%.6f'%valid_ls[-1][0],'valid_acc:%.4f'%valid_ls[-1][1])\n",
    "        train_loss_sum += train_ls[-1][0]\n",
    "        valid_loss_sum += valid_ls[-1][0]\n",
    "        train_acc_sum += train_ls[-1][1]\n",
    "        valid_acc_sum += valid_ls[-1][1]\n",
    "    print('#'*10,'最终k折交叉验证结果','#'*10) \n",
    "    ####体现步骤四#####\n",
    "    print('train_loss_sum:%.4f'%(train_loss_sum/k),'train_acc_sum:%.4f\\n'%(train_acc_sum/k),\\\n",
    "          'valid_loss_sum:%.4f'%(valid_loss_sum/k),'valid_acc_sum:%.4f'%(valid_acc_sum/k))\n",
    " \n",
    " \n",
    "#########训练函数##########\n",
    "def train(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate,weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], [] ##存储train_loss,test_loss\n",
    "    dataset = TraindataSet(train_features, train_labels) \n",
    "    train_iter = DataLoader(dataset, batch_size, shuffle=True) \n",
    "    ### 将数据封装成 Dataloder 对应步骤（2）\n",
    "    \n",
    "    #这里使用了Adam优化算法\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr= learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:  ###分批训练 \n",
    "            output  = net(X)\n",
    "            loss = loss_func(output,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        ### 得到每个epoch的 loss 和 accuracy \n",
    "        train_ls.append(log_rmse(0,net, train_features, train_labels)) \n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(1,net, test_features, test_labels))\n",
    "    #print(train_ls,test_ls)\n",
    "    return train_ls, test_ls\n",
    " \n",
    "def log_rmse(flag,net,x,y):\n",
    "    if flag == 1: ### valid 数据集\n",
    "        net.eval()\n",
    "    output = net(x)\n",
    "    result = torch.max(output,1)[1].view(y.size())\n",
    "    corrects = (result.data == y.data).sum().item()\n",
    "    accuracy = corrects*100.0/len(y)  #### 5 是 batch_size\n",
    "    loss = loss_func(output,y)\n",
    "    net.train()\n",
    "    \n",
    "    return (loss.data.item(),accuracy)\n",
    " \n",
    "#loss_func = nn.CrossEntropyLoss() ###申明loss函\n",
    "#k_fold(5,x,label) ### k=5,5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb982dd-6929-4a98-9923-8034310c8cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e48b48-be1f-49a8-bf0c-c25985393104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layer_1): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41f90a37-7f69-42f2-87fa-150ff3d64e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3119e5-e3ec-401f-a835-48c220775c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    \n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac1a65b2-c58c-4da8-ae68-d21904ca4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss:0.44812 | Acc: 79.338\n",
      "Epoch 002: | Loss:0.42257 | Acc: 81.280\n",
      "Epoch 003: | Loss:0.41679 | Acc: 81.605\n",
      "Epoch 004: | Loss:0.41955 | Acc: 81.541\n",
      "Epoch 005: | Loss:0.41693 | Acc: 81.745\n",
      "Epoch 006: | Loss:0.41910 | Acc: 82.274\n",
      "Epoch 007: | Loss:0.42109 | Acc: 82.401\n",
      "Epoch 008: | Loss:0.42413 | Acc: 82.306\n",
      "Epoch 009: | Loss:0.43154 | Acc: 82.682\n",
      "Epoch 010: | Loss:0.44352 | Acc: 82.236\n",
      "Epoch 011: | Loss:0.44631 | Acc: 82.720\n",
      "Epoch 012: | Loss:0.44567 | Acc: 82.331\n",
      "Epoch 013: | Loss:0.44522 | Acc: 83.006\n",
      "Epoch 014: | Loss:0.44640 | Acc: 82.752\n",
      "Epoch 015: | Loss:0.44798 | Acc: 82.433\n",
      "Epoch 016: | Loss:0.44653 | Acc: 82.503\n",
      "Epoch 017: | Loss:0.44701 | Acc: 82.522\n",
      "Epoch 018: | Loss:0.44550 | Acc: 82.459\n",
      "Epoch 019: | Loss:0.44446 | Acc: 82.694\n",
      "Epoch 020: | Loss:0.44201 | Acc: 82.503\n",
      "Epoch 021: | Loss:0.44390 | Acc: 82.924\n",
      "Epoch 022: | Loss:0.44446 | Acc: 82.656\n",
      "Epoch 023: | Loss:0.44303 | Acc: 82.898\n",
      "Epoch 024: | Loss:0.44372 | Acc: 82.516\n",
      "Epoch 025: | Loss:0.44272 | Acc: 82.592\n",
      "Epoch 026: | Loss:0.44331 | Acc: 82.822\n",
      "Epoch 027: | Loss:0.44612 | Acc: 82.510\n",
      "Epoch 028: | Loss:0.44218 | Acc: 82.892\n",
      "Epoch 029: | Loss:0.44190 | Acc: 82.688\n",
      "Epoch 030: | Loss:0.44697 | Acc: 82.662\n",
      "Epoch 031: | Loss:0.44479 | Acc: 82.439\n",
      "Epoch 032: | Loss:0.43975 | Acc: 82.732\n",
      "Epoch 033: | Loss:0.44247 | Acc: 82.873\n",
      "Epoch 034: | Loss:0.44331 | Acc: 82.395\n",
      "Epoch 035: | Loss:0.44478 | Acc: 82.408\n",
      "Epoch 036: | Loss:0.44227 | Acc: 82.975\n",
      "Epoch 037: | Loss:0.44083 | Acc: 82.930\n",
      "Epoch 038: | Loss:0.44425 | Acc: 82.815\n",
      "Epoch 039: | Loss:0.43917 | Acc: 83.064\n",
      "Epoch 040: | Loss:0.44162 | Acc: 82.955\n",
      "Epoch 041: | Loss:0.44553 | Acc: 82.790\n",
      "Epoch 042: | Loss:0.44231 | Acc: 82.745\n",
      "Epoch 043: | Loss:0.44312 | Acc: 82.777\n",
      "Epoch 044: | Loss:0.43859 | Acc: 83.172\n",
      "Epoch 045: | Loss:0.44100 | Acc: 83.064\n",
      "Epoch 046: | Loss:0.44287 | Acc: 82.682\n",
      "Epoch 047: | Loss:0.43966 | Acc: 83.051\n",
      "Epoch 048: | Loss:0.44486 | Acc: 82.586\n",
      "Epoch 049: | Loss:0.44305 | Acc: 82.955\n",
      "Epoch 050: | Loss:0.43835 | Acc: 82.917\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS + 1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = MLP_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    print(f'Epoch {e+0:03}: | Loss:{epoch_loss/len(train_loader):.5f} | Acc:{epoch_acc/len(train_loader): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20fdf22-7e26-4844-a9a0-7669bdbac29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(loader):\n",
    "    y_pred_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred= model(X_batch)\n",
    "            y_test_pred= torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    print(len(y_pred_list))\n",
    "    return y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c6a622a-3f7b-44d4-86d7-cd2f5b102be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def evl(x, y_pred_list):\n",
    "    cm = confusion_matrix(x, y_pred_list)\n",
    "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "    mcc = (cm[0,0]*cm[1,1]-cm[0,1]*cm[1,0])/sqrt((cm[0,0]+cm[0,1])*(cm[0,0]+cm[1,0])*(cm[1,1]+cm[0,1])*(cm[1,1]+cm[1,0]))\n",
    "    \n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print(f' Accurency:{acc}, MCC:{mcc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c6ef47e-83c2-43f7-8251-3b36e5e901ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4522\n",
      "Confusion Matrix:\n",
      "[[3135  848]\n",
      " [  84  455]]\n",
      " Accurency:0.7938965059708094, MCC:0.45161558183571765\n"
     ]
    }
   ],
   "source": [
    "y_pred_list2 = pred(test_loader)\n",
    "evl(y_test, y_pred_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94217050-24d7-449c-bb3a-7d618e4cc8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ML': conda)",
   "language": "python",
   "name": "python3810jvsc74a57bd0cff35c45cbab256606d2534f23a0be68c988e5f69921b5c9facd83c319944f6f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
