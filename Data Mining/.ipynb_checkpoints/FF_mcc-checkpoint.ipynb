{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ad89c5-ad69-418c-a064-1908d7914559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset   \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5b8957-3eb4-48a8-9e0c-3924bb2461b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/clause/Desktop/ZD/train.csv', index_col = 0)\n",
    "train = shuffle(train)\n",
    "x, label = train.iloc[:,:-1].values, train.iloc[:,-1].values\n",
    "x = torch.tensor(x.astype(np.float32))\n",
    "label = torch.tensor(label.astype(np.float32))\n",
    "\n",
    "test = pd.read_csv('/Users/clause/Desktop/ZD/test.csv', index_col = 0)\n",
    "X_test, y_test = test.iloc[:,:-1], test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b465678-4765-4640-a625-621bd8b715f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(8, 64)\n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_3 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = 0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28071b37-239a-4249-9b32-aa673a9aadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.len = len(y_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f561dd-ff54-4f14-b988-a721c4988952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k fold     \n",
    "def get_k_fold_data(k, i, X, y): \n",
    "    # Return the training and verification data needed for the i-th fold cross-validation, \n",
    "    # X_train is the training data, X_valid is the verification data\n",
    "    assert k > 1\n",
    "    # All data / nuber of fold\n",
    "    fold_size = X.shape[0] // k  \n",
    "    \n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size) # slice(start,end,step) \n",
    "        # idx is the valid of every folds\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i: # valid of #i fold\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat((X_train, X_part), dim=0) #dim=0, add row, link by column\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    #print(X_train.size(),X_valid.size())\n",
    "    return X_train, y_train, X_valid,y_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fda0d43-03ee-491b-909b-05d342fe1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k, X_train, y_train, num_epochs=50,learning_rate=0.001, weight_decay=0, batch_size=64):\n",
    "    \n",
    "    # train set part\n",
    "    train_loss_sum, valid_loss_sum = 0, 0\n",
    "    train_acc_sum ,valid_acc_sum = 0,0\n",
    "    train_mcc_sum ,valid_mcc_sum = 0,0\n",
    "    \n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train) # get data after k-fold\n",
    "        net =  Net()\n",
    "        # train\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\\\n",
    "                                   weight_decay, batch_size) \n",
    "        t_acc = float(train_ls[-1][1])\n",
    "        v_acc = float(valid_ls[-1][1])\n",
    "        t_mcc  = float(train_ls[-1][2])\n",
    "        v_mcc = float(valid_ls[-1][2])\n",
    "        \n",
    "        print('*'*25,'fold',i+1,'*'*25)\n",
    "        print('train_loss:%.6f'%train_ls[-1][0],'train_acc:%.4f'%t_acc,'train_mcc:%.4f\\n'%t_mcc, \\\n",
    "              'valid loss:%.6f'%valid_ls[-1][0],'valid_acc:%.4f'%v_acc,'valid_mcc:%.4f'%v_mcc)\n",
    "        \n",
    "        train_loss_sum += train_ls[-1][0]\n",
    "        valid_loss_sum += valid_ls[-1][0]\n",
    "        train_acc_sum += t_acc\n",
    "        valid_acc_sum += v_acc\n",
    "        train_mcc_sum += t_mcc\n",
    "        valid_mcc_sum += v_mcc\n",
    "    \n",
    "    print('*'*25,'final result','*'*25) \n",
    "    print('train_loss_sum:%.4f'%(train_loss_sum/k),'train_acc_sum:%.4f'%(train_acc_sum/k),'train_mcc_sum:%.4f\\n'%(train_mcc_sum/k),\\\n",
    "          'valid_loss_sum:%.4f'%(valid_loss_sum/k),'valid_acc_sum:%.4f'%(valid_acc_sum/k),'valid_mcc_sum:%.4f'%(valid_mcc_sum/k))\n",
    "    \n",
    "    # test set part\n",
    "    test_data = testData(torch.FloatTensor(X_test.values))\n",
    "    test_loader = DataLoader(dataset = test_data, batch_size = 1)\n",
    "    y_pred_list = []\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            y_test_pred= net(X_batch)\n",
    "            y_test_pred= torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    cm, acc, mcc = evaluate(y_test, y_pred_list)\n",
    "    print()\n",
    "    print('Confusion Matrix of test set:')\n",
    "    print(cm)\n",
    "    print(f' Accurency:{acc}, MCC:{mcc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b900b33-be2e-4f5b-88f5-05571646b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate,weight_decay, batch_size):\n",
    "    \n",
    "    train_ls, test_ls = [], []\n",
    "    \n",
    "    dataset = trainData(train_features, train_labels) \n",
    "    train_iter = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr= learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X, y in train_iter:  # train by batch\n",
    "            output  = net(X)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_func(output,y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # get loss & accuracy of each epoch\n",
    "        train_ls.append(mcc(0,net, train_features, train_labels)) \n",
    "        if test_labels is not None:\n",
    "            test_ls.append(mcc(1,net, test_features, test_labels))\n",
    "    \n",
    "    return train_ls, test_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735a0bb7-74e4-4e65-ad83-dceaeacdeffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(flag,net,x,y):\n",
    "    if flag == 1: ### valid 数据集\n",
    "        net.eval()\n",
    "    else:\n",
    "        net.train()\n",
    "    #np.seterr(divide='ignore', invalid='ignore')\n",
    "    output = net(x)\n",
    "    result = torch.round(torch.sigmoid(output))\n",
    "    loss = loss_func(output,y.unsqueeze(1))\n",
    "    \n",
    "    cm, acc, mcc = evaluate(y.detach().numpy(), result.detach().numpy())\n",
    "    \n",
    "    #print(cm)\n",
    "    return (loss.data.item(), acc, mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84fef5b4-54f5-44da-bf8d-bd0857bbd024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, y):\n",
    "    cm = confusion_matrix(x, y)\n",
    "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "    upper = cm[0,0]*cm[1,1]-cm[0,1]*cm[1,0]\n",
    "    lower = sqrt((cm[0,0]+cm[0,1])*(cm[0,0]+cm[1,0])*(cm[1,1]+cm[0,1])*(cm[1,1]+cm[1,0]))\n",
    "    \n",
    "    if (cm[0,0]+cm[0,1])*(cm[0,0]+cm[1,0])*(cm[1,1]+cm[0,1])*(cm[1,1]+cm[1,0]) == 0:\n",
    "        mcc = 0\n",
    "    else:\n",
    "        mcc = upper / lower\n",
    "    return cm, acc, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5c35680-4ead-4123-9f48-546699b7b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* fold 1 *************************\n",
      "train_loss:0.268360 train_acc:0.8806 train_mcc:0.7622\n",
      " valid loss:0.376408 valid_acc:0.8520 valid_mcc:0.7056\n",
      "************************* fold 2 *************************\n",
      "train_loss:0.280465 train_acc:0.8744 train_mcc:0.7489\n",
      " valid loss:0.392208 valid_acc:0.8420 valid_mcc:0.6844\n",
      "************************* fold 3 *************************\n",
      "train_loss:0.291938 train_acc:0.8672 train_mcc:0.7345\n",
      " valid loss:0.393149 valid_acc:0.8405 valid_mcc:0.6815\n",
      "************************* fold 4 *************************\n",
      "train_loss:0.279358 train_acc:0.8805 train_mcc:0.7612\n",
      " valid loss:0.389929 valid_acc:0.8330 valid_mcc:0.6665\n",
      "************************* fold 5 *************************\n",
      "train_loss:0.279183 train_acc:0.8815 train_mcc:0.7632\n",
      " valid loss:0.388477 valid_acc:0.8415 valid_mcc:0.6829\n",
      "************************* final result *************************\n",
      "train_loss_sum:0.2799 train_acc_sum:0.8768 train_mcc_sum:0.7540\n",
      " valid_loss_sum:0.3880 valid_acc_sum:0.8418 valid_mcc_sum:0.6842\n",
      "\n",
      "Confusion Matrix of test set:\n",
      "[[3265  718]\n",
      " [ 134  405]]\n",
      " Accurency:0.8115877930119416, MCC:0.42831718630485255\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "k_fold(5, x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7738f-3ba6-437e-94f4-d7b46127005c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ML': conda)",
   "language": "python",
   "name": "python3810jvsc74a57bd0cff35c45cbab256606d2534f23a0be68c988e5f69921b5c9facd83c319944f6f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
